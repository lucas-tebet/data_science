{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PROJETO - Detecção de fraudes em cartões de crédito.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO/t/Dgj7HJp7sW20LbBcDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucas-tebet/sigmoidal_data_science/blob/master/PROJETO_Detec%C3%A7%C3%A3o_de_fraudes_em_cart%C3%B5es_de_cr%C3%A9dito.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dNzFkD-EUaG",
        "colab_type": "text"
      },
      "source": [
        "#Contextualização\n",
        "\n",
        "Atualmente o tema de fraudes em operações financeiras envolvendo cartões de crédito vem ganhando cada vez mais relevância.\n",
        "\n",
        "O *Machine Learning* pode ser utilizado a favor deste segmento com a finalidade de identificar transações que possuem características mais próximas a aquelas rotuladas como \"fraude\". Dessa forma, o prejuízo com essas operações pode ser minimizado bem como a quantidade de \"falsos positivos\".\n",
        "\n",
        "E é justamente isso que iremos trazer nesse projeto: faremos uma previsão entre as operações genuínas e fraudulentas e compararemos com os dados históricos, através de um modelo de ***Machine Learning***. Quanto mais próximos forem os números estimados dos números realizados, melhor será o nosso resultado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAK8HfaJGBK-",
        "colab_type": "text"
      },
      "source": [
        "#Obtenção dos dados\n",
        "Os dados utilizados neste projeto são divulgados por empresas europeias de cartão de crédito. São todos dados reais, porém anônimos, a fim de contribuir para projetos de Data Science.\n",
        "\n",
        "Por conta de sigilo, os *features* deste *dataset* foram descaracterizados e são todos numéricos e por isso os nomes das colunas são representados por V1, V2, V3 ..., V28.\n",
        "\n",
        "Visualmente, essas variáveis não significam nada para nós, porém podemos compará-las e verificar quais são seus comportamentos em transações genuínas e fraudulentas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCKZh1GWESw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importação das bibliotecas necessárias para o projeto\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#configuração dos estilos de gráfico do Seaborn\n",
        "sns.set_style(\"dark\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7Jit4mLJqHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importação do dataset para um dataframe\n",
        "\n",
        "df = pd.read_csv(\"https://www.dropbox.com/s/b44o3t3ehmnx2b7/creditcard.csv?dl=1\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1auoaDtOQV0",
        "colab_type": "text"
      },
      "source": [
        "Depois de configurar as bibliotecas necessárias e importar o dataset, estamos prontos para fazer a análise do projeto, usando o modelo de *Machine Learning*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26XdRUJbPFgV",
        "colab_type": "text"
      },
      "source": [
        "#Análise exploratória\n",
        "\n",
        "Conforme na tabela abaixo, nas 5 primeiras entradas do *dataframe* é logo possível verificar as features descaracterizadas em valores numéricos (por sigilo). Somente as colunas `Time`e `Amount` foram preservadas. \n",
        "\n",
        "A variável `Time` é referente ao tempo em segundos em que a transação foi realizada. A base tem 2 dias. \n",
        "\n",
        "A variável `Amount` é referente a quantidade em valor monetário em que a transação foi realizada. \n",
        "\n",
        "A coluna *target* para a nossa análise é a coluna `Class` que mostra:\n",
        "\n",
        "* 0: a transação foi genuína\n",
        "* 1: a transação foi fraudulenta\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nP-jIz3N9Y3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "956ce78a-37f5-49d4-b1c9-3a2ba5871150"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DS1kSvTGS_Bi",
        "colab_type": "text"
      },
      "source": [
        "A base de dados não possui nenhum valor nulo, como podemos verificar abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR_1s3SSTEHh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c06d66f5-604a-4584-85f1-3f5ea45a816f"
      },
      "source": [
        "print(\"A soma de todas as células nulas no dataframe é:\", df.isnull().sum().sum())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A soma de todas as células nulas no dataframe é: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl9Mf2rkAlQ7",
        "colab_type": "text"
      },
      "source": [
        "Para verificar as informações estatísticas da nossa base de dados, usamos o método `describe()`, conforme abaixo. Nele conseguimos ver que a *feature* tempo vai de 0 à 172.792, o que representa 2 dias. \n",
        "\n",
        "Com essas informações, podemos perceber também que as variáveis explícitas (`Time`, `Amount` e `Class`) não apresentam *outliers* e por isso, não há necessidade de fazer uma \"limpeza\" nos dados. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kX_T19FAkuW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "d715ebd3-f4f1-470f-e37e-06c2803927ba"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>284807.000000</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>2.848070e+05</td>\n",
              "      <td>284807.000000</td>\n",
              "      <td>284807.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>94813.859575</td>\n",
              "      <td>3.919560e-15</td>\n",
              "      <td>5.688174e-16</td>\n",
              "      <td>-8.769071e-15</td>\n",
              "      <td>2.782312e-15</td>\n",
              "      <td>-1.552563e-15</td>\n",
              "      <td>2.010663e-15</td>\n",
              "      <td>-1.694249e-15</td>\n",
              "      <td>-1.927028e-16</td>\n",
              "      <td>-3.137024e-15</td>\n",
              "      <td>1.768627e-15</td>\n",
              "      <td>9.170318e-16</td>\n",
              "      <td>-1.810658e-15</td>\n",
              "      <td>1.693438e-15</td>\n",
              "      <td>1.479045e-15</td>\n",
              "      <td>3.482336e-15</td>\n",
              "      <td>1.392007e-15</td>\n",
              "      <td>-7.528491e-16</td>\n",
              "      <td>4.328772e-16</td>\n",
              "      <td>9.049732e-16</td>\n",
              "      <td>5.085503e-16</td>\n",
              "      <td>1.537294e-16</td>\n",
              "      <td>7.959909e-16</td>\n",
              "      <td>5.367590e-16</td>\n",
              "      <td>4.458112e-15</td>\n",
              "      <td>1.453003e-15</td>\n",
              "      <td>1.699104e-15</td>\n",
              "      <td>-3.660161e-16</td>\n",
              "      <td>-1.206049e-16</td>\n",
              "      <td>88.349619</td>\n",
              "      <td>0.001727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>47488.145955</td>\n",
              "      <td>1.958696e+00</td>\n",
              "      <td>1.651309e+00</td>\n",
              "      <td>1.516255e+00</td>\n",
              "      <td>1.415869e+00</td>\n",
              "      <td>1.380247e+00</td>\n",
              "      <td>1.332271e+00</td>\n",
              "      <td>1.237094e+00</td>\n",
              "      <td>1.194353e+00</td>\n",
              "      <td>1.098632e+00</td>\n",
              "      <td>1.088850e+00</td>\n",
              "      <td>1.020713e+00</td>\n",
              "      <td>9.992014e-01</td>\n",
              "      <td>9.952742e-01</td>\n",
              "      <td>9.585956e-01</td>\n",
              "      <td>9.153160e-01</td>\n",
              "      <td>8.762529e-01</td>\n",
              "      <td>8.493371e-01</td>\n",
              "      <td>8.381762e-01</td>\n",
              "      <td>8.140405e-01</td>\n",
              "      <td>7.709250e-01</td>\n",
              "      <td>7.345240e-01</td>\n",
              "      <td>7.257016e-01</td>\n",
              "      <td>6.244603e-01</td>\n",
              "      <td>6.056471e-01</td>\n",
              "      <td>5.212781e-01</td>\n",
              "      <td>4.822270e-01</td>\n",
              "      <td>4.036325e-01</td>\n",
              "      <td>3.300833e-01</td>\n",
              "      <td>250.120109</td>\n",
              "      <td>0.041527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-5.640751e+01</td>\n",
              "      <td>-7.271573e+01</td>\n",
              "      <td>-4.832559e+01</td>\n",
              "      <td>-5.683171e+00</td>\n",
              "      <td>-1.137433e+02</td>\n",
              "      <td>-2.616051e+01</td>\n",
              "      <td>-4.355724e+01</td>\n",
              "      <td>-7.321672e+01</td>\n",
              "      <td>-1.343407e+01</td>\n",
              "      <td>-2.458826e+01</td>\n",
              "      <td>-4.797473e+00</td>\n",
              "      <td>-1.868371e+01</td>\n",
              "      <td>-5.791881e+00</td>\n",
              "      <td>-1.921433e+01</td>\n",
              "      <td>-4.498945e+00</td>\n",
              "      <td>-1.412985e+01</td>\n",
              "      <td>-2.516280e+01</td>\n",
              "      <td>-9.498746e+00</td>\n",
              "      <td>-7.213527e+00</td>\n",
              "      <td>-5.449772e+01</td>\n",
              "      <td>-3.483038e+01</td>\n",
              "      <td>-1.093314e+01</td>\n",
              "      <td>-4.480774e+01</td>\n",
              "      <td>-2.836627e+00</td>\n",
              "      <td>-1.029540e+01</td>\n",
              "      <td>-2.604551e+00</td>\n",
              "      <td>-2.256568e+01</td>\n",
              "      <td>-1.543008e+01</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>54201.500000</td>\n",
              "      <td>-9.203734e-01</td>\n",
              "      <td>-5.985499e-01</td>\n",
              "      <td>-8.903648e-01</td>\n",
              "      <td>-8.486401e-01</td>\n",
              "      <td>-6.915971e-01</td>\n",
              "      <td>-7.682956e-01</td>\n",
              "      <td>-5.540759e-01</td>\n",
              "      <td>-2.086297e-01</td>\n",
              "      <td>-6.430976e-01</td>\n",
              "      <td>-5.354257e-01</td>\n",
              "      <td>-7.624942e-01</td>\n",
              "      <td>-4.055715e-01</td>\n",
              "      <td>-6.485393e-01</td>\n",
              "      <td>-4.255740e-01</td>\n",
              "      <td>-5.828843e-01</td>\n",
              "      <td>-4.680368e-01</td>\n",
              "      <td>-4.837483e-01</td>\n",
              "      <td>-4.988498e-01</td>\n",
              "      <td>-4.562989e-01</td>\n",
              "      <td>-2.117214e-01</td>\n",
              "      <td>-2.283949e-01</td>\n",
              "      <td>-5.423504e-01</td>\n",
              "      <td>-1.618463e-01</td>\n",
              "      <td>-3.545861e-01</td>\n",
              "      <td>-3.171451e-01</td>\n",
              "      <td>-3.269839e-01</td>\n",
              "      <td>-7.083953e-02</td>\n",
              "      <td>-5.295979e-02</td>\n",
              "      <td>5.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>84692.000000</td>\n",
              "      <td>1.810880e-02</td>\n",
              "      <td>6.548556e-02</td>\n",
              "      <td>1.798463e-01</td>\n",
              "      <td>-1.984653e-02</td>\n",
              "      <td>-5.433583e-02</td>\n",
              "      <td>-2.741871e-01</td>\n",
              "      <td>4.010308e-02</td>\n",
              "      <td>2.235804e-02</td>\n",
              "      <td>-5.142873e-02</td>\n",
              "      <td>-9.291738e-02</td>\n",
              "      <td>-3.275735e-02</td>\n",
              "      <td>1.400326e-01</td>\n",
              "      <td>-1.356806e-02</td>\n",
              "      <td>5.060132e-02</td>\n",
              "      <td>4.807155e-02</td>\n",
              "      <td>6.641332e-02</td>\n",
              "      <td>-6.567575e-02</td>\n",
              "      <td>-3.636312e-03</td>\n",
              "      <td>3.734823e-03</td>\n",
              "      <td>-6.248109e-02</td>\n",
              "      <td>-2.945017e-02</td>\n",
              "      <td>6.781943e-03</td>\n",
              "      <td>-1.119293e-02</td>\n",
              "      <td>4.097606e-02</td>\n",
              "      <td>1.659350e-02</td>\n",
              "      <td>-5.213911e-02</td>\n",
              "      <td>1.342146e-03</td>\n",
              "      <td>1.124383e-02</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>139320.500000</td>\n",
              "      <td>1.315642e+00</td>\n",
              "      <td>8.037239e-01</td>\n",
              "      <td>1.027196e+00</td>\n",
              "      <td>7.433413e-01</td>\n",
              "      <td>6.119264e-01</td>\n",
              "      <td>3.985649e-01</td>\n",
              "      <td>5.704361e-01</td>\n",
              "      <td>3.273459e-01</td>\n",
              "      <td>5.971390e-01</td>\n",
              "      <td>4.539234e-01</td>\n",
              "      <td>7.395934e-01</td>\n",
              "      <td>6.182380e-01</td>\n",
              "      <td>6.625050e-01</td>\n",
              "      <td>4.931498e-01</td>\n",
              "      <td>6.488208e-01</td>\n",
              "      <td>5.232963e-01</td>\n",
              "      <td>3.996750e-01</td>\n",
              "      <td>5.008067e-01</td>\n",
              "      <td>4.589494e-01</td>\n",
              "      <td>1.330408e-01</td>\n",
              "      <td>1.863772e-01</td>\n",
              "      <td>5.285536e-01</td>\n",
              "      <td>1.476421e-01</td>\n",
              "      <td>4.395266e-01</td>\n",
              "      <td>3.507156e-01</td>\n",
              "      <td>2.409522e-01</td>\n",
              "      <td>9.104512e-02</td>\n",
              "      <td>7.827995e-02</td>\n",
              "      <td>77.165000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>172792.000000</td>\n",
              "      <td>2.454930e+00</td>\n",
              "      <td>2.205773e+01</td>\n",
              "      <td>9.382558e+00</td>\n",
              "      <td>1.687534e+01</td>\n",
              "      <td>3.480167e+01</td>\n",
              "      <td>7.330163e+01</td>\n",
              "      <td>1.205895e+02</td>\n",
              "      <td>2.000721e+01</td>\n",
              "      <td>1.559499e+01</td>\n",
              "      <td>2.374514e+01</td>\n",
              "      <td>1.201891e+01</td>\n",
              "      <td>7.848392e+00</td>\n",
              "      <td>7.126883e+00</td>\n",
              "      <td>1.052677e+01</td>\n",
              "      <td>8.877742e+00</td>\n",
              "      <td>1.731511e+01</td>\n",
              "      <td>9.253526e+00</td>\n",
              "      <td>5.041069e+00</td>\n",
              "      <td>5.591971e+00</td>\n",
              "      <td>3.942090e+01</td>\n",
              "      <td>2.720284e+01</td>\n",
              "      <td>1.050309e+01</td>\n",
              "      <td>2.252841e+01</td>\n",
              "      <td>4.584549e+00</td>\n",
              "      <td>7.519589e+00</td>\n",
              "      <td>3.517346e+00</td>\n",
              "      <td>3.161220e+01</td>\n",
              "      <td>3.384781e+01</td>\n",
              "      <td>25691.160000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Time            V1  ...         Amount          Class\n",
              "count  284807.000000  2.848070e+05  ...  284807.000000  284807.000000\n",
              "mean    94813.859575  3.919560e-15  ...      88.349619       0.001727\n",
              "std     47488.145955  1.958696e+00  ...     250.120109       0.041527\n",
              "min         0.000000 -5.640751e+01  ...       0.000000       0.000000\n",
              "25%     54201.500000 -9.203734e-01  ...       5.600000       0.000000\n",
              "50%     84692.000000  1.810880e-02  ...      22.000000       0.000000\n",
              "75%    139320.500000  1.315642e+00  ...      77.165000       0.000000\n",
              "max    172792.000000  2.454930e+00  ...   25691.160000       1.000000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3r74qv_xTz0K",
        "colab_type": "text"
      },
      "source": [
        "Abaixo vamos dar uma olhada na quantidade de operações genuínas / fraudulentas. Como é de se imaginar, a discrepância entre os resultados é nitido e pode ser observado no gráfico. \n",
        "\n",
        "No período de 2 dias, a quantidade de transações fraudulentas representou 0,17%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PamkCU1eT3lz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "f7abb25e-b99f-4b04-b306-c25be61e70f9"
      },
      "source": [
        "#verificar o balanceamento dos resultados\n",
        "print(df.Class.value_counts())\n",
        "print(\"\\nPorcentagem de transações fraudulentas: {:.4%}\\n\".format(df[df.Class==1].shape[0] / df.shape[0]))\n",
        "\n",
        "#gráfico para ilustrar as classes das operações\n",
        "fig, ax = plt.subplots()\n",
        "sns.countplot(\"Class\", data=df, ax=ax)\n",
        "ax.set_title(\"Distribuição das Classes\")\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    284315\n",
            "1       492\n",
            "Name: Class, dtype: int64\n",
            "\n",
            "Porcentagem de transações fraudulentas: 0.1727%\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qX56bzBxmQmG",
        "colab_type": "text"
      },
      "source": [
        "#Tratamento dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLJEuTTwri9j",
        "colab_type": "text"
      },
      "source": [
        "##Padronização dos dados\n",
        "Antes de partirmos para o nosso modelo de **Regressão Logística**, devemos tratar as nossas variáveis. \n",
        "\n",
        "Isso se deve ao fato de que, embora as variáveis V1 ... V28 já estarem em uma mesma escala, as variáveis `Time` e `Amount` não estão. Portanto é importante que todas as variáveis estejam na mesma escala, para não apresentar nenhum erro no nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_k2-C1WozF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "4686d833-a7b0-430a-c89d-23d264f9019a"
      },
      "source": [
        "#padronização das variáveis Time e Amount\n",
        "\n",
        "df_clean = df.copy()\n",
        "\n",
        "std_scaler = StandardScaler()\n",
        "df_clean['std_time'] = std_scaler.fit_transform(df_clean['Time'].values.reshape(-1,1))\n",
        "df_clean['std_amount'] = std_scaler.fit_transform(df_clean['Amount'].values.reshape(-1,1))\n",
        "\n",
        "df_clean.drop(['Time', 'Amount'], axis = 1, inplace=True)\n",
        "\n",
        "#5 primeiras entradas\n",
        "df_clean.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "      <th>std_time</th>\n",
              "      <th>std_amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996583</td>\n",
              "      <td>0.244964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996583</td>\n",
              "      <td>-0.342475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996562</td>\n",
              "      <td>1.160686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996562</td>\n",
              "      <td>0.140534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.996541</td>\n",
              "      <td>-0.073403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         V1        V2        V3  ...  Class  std_time  std_amount\n",
              "0 -1.359807 -0.072781  2.536347  ...      0 -1.996583    0.244964\n",
              "1  1.191857  0.266151  0.166480  ...      0 -1.996583   -0.342475\n",
              "2 -1.358354 -1.340163  1.773209  ...      0 -1.996562    1.160686\n",
              "3 -0.966272 -0.185226  1.792993  ...      0 -1.996562    0.140534\n",
              "4 -1.158233  0.877737  1.548718  ...      0 -1.996541   -0.073403\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY-UV-6UrTKT",
        "colab_type": "text"
      },
      "source": [
        "##Divisão dos dados\n",
        "Após isso, dividiremos os nossos dados entre **Treino** e **Teste**. Assim podemos rodar o nosso modelo de *Machine Learing*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjA-1KGarVUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df_clean.drop('Class', axis = 1)\n",
        "y = df_clean['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2nUBhlFg1Kg",
        "colab_type": "text"
      },
      "source": [
        "##Balanceamento dos dados\n",
        "\n",
        "Chamamos essa discrepância entre as classes 0 (transações genuínas) e 1 (transações fraudulentas) de **Dados Desbalanceados**. \n",
        "\n",
        "Se fizermos o nosso modelo de *Machine Learning* para que ele aprenda com esses dados originais, ele será enviesado e terá uma tendência muito maior de classificar a transação como **genuína**, por conta da sua grande quantidade. \n",
        "\n",
        "Por isso, é de extrema importância utilizamos técnicas para lidar com esses dados desbalanceados. \n",
        "\n",
        "A técnica que iremos utilizar nesse projeto é a de ***Under Sampling***. Resumidamente, o modelo irá eliminar aleatoriamente entradas com a classe majoritária (0) até que seu número se iguale o da classe minoritária (1).\n",
        "\n",
        "Utilizaremos a biblioteca `imblearn` para fazer o *Under Sampling*, conforme abaixo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gP8HHSli60-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "d21a108e-ce70-470b-af0d-e14d2fb79417"
      },
      "source": [
        "rus = RandomUnderSampler()\n",
        "\n",
        "X_rus , y_rus = rus.fit_sample(X_train, y_train)\n",
        "\n",
        "print(pd.Series(y_rus).value_counts())\n",
        "\n",
        "sns.countplot(y_rus);"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    374\n",
            "0    374\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nm6zBIY2KH1",
        "colab_type": "text"
      },
      "source": [
        "#Modelo de *Machine Learning*\n",
        "Agora que os dados estão \"prontos\" para serem utilizados, vamos aplicar o modelo de **Regressão Logística**, por ser um tipo de aprendizado supervisionado (existe uma variável alvo: `Class`) e essa variável é dada como \"sim\" ou \"não\", ou seja, é de **Classificação**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hvqJNNX21UY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#escolha do modelo de Regressão Logística\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#instanciar a classe do modelo\n",
        "model = LogisticRegression()\n",
        "\n",
        "#treinar o modelo\n",
        "model.fit(X_rus, y_rus)\n",
        "\n",
        "#aplicar o modelo aos novos dados\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61czsbAk4wUA",
        "colab_type": "text"
      },
      "source": [
        "O modelo foi treinado com os valores resultantes do *under sampling* e para saber o quão bom esse modelo se apresentou, devemos utilizar algumas métricas. \n",
        "\n",
        "Abaixo podemos ver no relatório a precisão e o recall. Falaremos dessas métricas na conclusão.\n",
        "\n",
        "Complementando, a Matriz de Confusão ilustra esse resultado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo6Rk-gK5C3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "69815e5d-f637-41c6-e50c-1178bcb2df30"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred, digits=4))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9999    0.9653    0.9823     71084\n",
            "           1     0.0426    0.9322    0.0815       118\n",
            "\n",
            "    accuracy                         0.9652     71202\n",
            "   macro avg     0.5213    0.9487    0.5319     71202\n",
            "weighted avg     0.9983    0.9652    0.9808     71202\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNhPosgU60Hx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "87c74670-f5ae-42a5-fa4b-d2e068bacb3f"
      },
      "source": [
        "#plotar matriz de confusão\n",
        "from sklearn.metrics import confusion_matrix\n",
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, cbar=False, square=True)\n",
        "ax.set_title('Matriz de Confusão')\n",
        "ax.set_xlabel('Previsto')\n",
        "ax.set_ylabel('Verdadeiro')\n",
        "plt.show()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUoAXlsP9z9t",
        "colab_type": "text"
      },
      "source": [
        "#Conclusão\n",
        "\n",
        "Podemos concluir que esse modelo de *Machine Learning* nos trouxe um ótimo resultado para identificar quando uma transação é fraudulenta. \n",
        "\n",
        "Vamos entrar em um pouco mais de detalhe para entender o que realmente aconteceu.\n",
        "\n",
        "###Transações genuínas\n",
        "Como chamamos anteriormente de **`Class` = 0**, essa classificação teve uma Precisão de 99,98%. Isso significa que de **todas** as transações **previstas** como genuínas, 99,98% eram de fato genuínas. \n",
        "\n",
        "###Transações fradulentas\n",
        "Chamada de **`Class` = 1**, a sua Precisão foi de 4,26%, o que segnifica que de todas as transações previstas como fraudulentas, 4,26% eram de fato fraudulentas, o restante podemos chamar de \"falsos positivos\". \n",
        "\n",
        "Mas a característica mais importante aqui é o *Recall*, cujo valor foi de 93,22%. Isso quer dizer que de todas as transações que foram realmente rotuladas como fraude, conseguimos prever 93,22% das vezes. "
      ]
    }
  ]
}